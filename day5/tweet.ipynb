{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"H1HAPkY6BsUBotSMtizThA7NP\" \n",
    "consumer_secret = \"6HMb84I01d4vCa9h7BpPtU79z3sk0vYVZfPH8R9ZjUjpGje8QJ\"\n",
    "access_key = \"1269208732174626817-5Hfcb4CTMzVRJsSTa3cRtJm7ovC3Td\"\n",
    "access_secret = \"xDLhzGKiVG3YWyvz8E5Rz6nChnC6XtpbotJoN8ftwVV4Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Aintshitjunior: i hate humans bro .. i shouldve been a bike or some shit\n",
      "RT @Aintshitjunior: i hate humans bro .. i shouldve been a bike or some shit\n",
      "I'm starting to hate wishes.\n",
      "RT @Aintshitjunior: i hate humans bro .. i shouldve been a bike or some shit\n",
      "RT @sopheanordin: Honestly I prefer not to be around people when Iâ€™m not in the mood, because I hate the fact that I canâ€™t control my wordsâ€¦\n",
      "RT @DearSplenda: why don't all the conservatives who hate unions also hate police unions\n",
      "RT @1luv95: I hate being shy like this shit be embarassing sometimes https://t.co/jIlrsvTFgv\n",
      "RT @icecube: Over half of the U.S. Senate doesnâ€™t think this is a Hate Crime. Guess which half? https://t.co/hbLZC6IoNT\n",
      "RT @wafilahh: hate the sin, not the sinner. look at the advice, not the adviser.\n",
      "RT @localblackgirl: i hate this. it screams â€œiâ€™m allowed to fetishize black men because iâ€™m out here supporting themâ€ ðŸ˜\n"
     ]
    }
   ],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "              q=\"hate\",\n",
    "              lang=\"en\",\n",
    "              since=\"2020-05-1\").items(10)\n",
    "\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "              q=\"hate\",\n",
    "              lang=\"en\",\n",
    "              since=\"2020-05-1\").items(500)\n",
    "info = [[tweet.text] for tweet in tweets]\n",
    "\n",
    "tweet_text = pd.DataFrame(data=info, \n",
    "                    columns=[\"tweet\"])\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(input_txt, pattern):                                          \n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "def clean_tweets(lst):\n",
    "    lst = np.vectorize(remove)(lst, \"\\r\")                                  \n",
    "    lst = np.vectorize(remove)(lst, \"\\n\")\n",
    "    lst = np.vectorize(remove)(lst, \"RT @[\\w]*:\")                        \n",
    "    lst = np.vectorize(remove)(lst, \"@[\\w]*\")                             \n",
    "    lst = np.vectorize(remove)(lst, \"https?://[A-Za-z0-9./]*\")           \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text['clean']= clean_tweets(tweet_text['tweet'])   #Cleaned Tweets are kept in separate coloumn clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "tweet_text['clean'].apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info1=tweet_text['clean'].apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=info1,columns=[\"clean\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizing = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')                                                                   #words to base form\n",
    "df['clean'] = df['clean'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "df['clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer     #try\n",
    "\n",
    "#nltk.download('vader_lexicon')\n",
    "#sid = SentimentIntensityAnalyzer()\n",
    "#for sentence in tweet_text[\"clean\"]:\n",
    " #   print(sentence)\n",
    "  #  ss = sid.polarity_scores(sentence)\n",
    "   # for k in ss:\n",
    "        #print('{0}: {1}, '.format(k, ss[k]), end='') \n",
    "    #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob                                               #polarrity -:negative +:positive &subjectivity\n",
    "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "df['polarity'] = df['clean'].apply(polarity)\n",
    "df['subjectivity'] = df['clean'].apply(subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(x):                                                              #0 neutral 1:pos -1:neg\n",
    " if x > 0:\n",
    "   return 1\n",
    " elif x == 0:\n",
    "   return 0\n",
    " else:\n",
    "   return -1\n",
    "df['result'] = df['polarity'].apply(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0:neither 1:non-toxic -1:toxic(negative tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
